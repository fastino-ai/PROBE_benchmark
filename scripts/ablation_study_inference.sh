#!/bin/bash
# LLM Ablation Study - Inference
# Runs GPT-5 inference on data generated by each LLM
#
# This script evaluates a single inference model (GPT-5) on datasets
# generated by different LLMs to measure data quality impact.

set -e

echo "=========================================="
echo "PROBE LLM Ablation Study - Inference"
echo "=========================================="
echo ""

# Configuration
INFERENCE_MODEL="gpt-5"

# Data generation models
DATA_GEN_MODELS=("gpt5mini" "gpt41" "claude")

echo "Running inference with $INFERENCE_MODEL on each generated dataset..."
echo ""

for model in "${DATA_GEN_MODELS[@]}"; do
    # Find the latest generated data directory (full batch path)
    BATCH_DIR=$(find generated_data -type d -path "*ablation_${model}*batch" 2>/dev/null | sort -r | head -1)
    
    if [ -z "$BATCH_DIR" ]; then
        echo "⚠️  No batch directory found for ablation_${model}, skipping..."
        continue
    fi
    
    # Point to the inputs subdirectory (as per README convention)
    DATA_DIR="${BATCH_DIR}/inputs"
    
    if [ ! -d "$DATA_DIR" ]; then
        echo "⚠️  No inputs directory found at $DATA_DIR, skipping..."
        continue
    fi
    
    echo ""
    echo "▶ Running LLM baseline inference on data generated by: $model"
    echo "  Batch directory: $BATCH_DIR"
    echo "  Data directory: $DATA_DIR"
    echo "  Inference model: $INFERENCE_MODEL"
    echo ""
    
    # Run inference with PYTHONPATH set for module imports
    # Python extracts Path(data_dir).name for results, so all use same 'inputs' dirname
    # Since script runs sequentially, each model's results complete before next starts
    PYTHONPATH="${PYTHONPATH:+${PYTHONPATH}:}$(pwd)" doppler run -- python baselines/llm/run_native_batch_evaluation.py \
        --models "$INFERENCE_MODEL" \
        --data_dir "$DATA_DIR"
    
    # Move completed results to model-specific directory to prevent overwriting
    BATCH_NAME=$(basename "$BATCH_DIR")
    if [ -d "results/inputs" ]; then
        # Remove destination if it exists, then move
        rm -rf "results/${BATCH_NAME}_${model}"
        mv "results/inputs" "results/${BATCH_NAME}_${model}"
        echo "  → Moved results to: results/${BATCH_NAME}_${model}/"
    fi
    
    echo "✓ Inference submitted for: $model"
    echo ""
done

echo ""
echo "=========================================="
echo "Inference Complete!"
echo "=========================================="
echo ""
echo "Predictions saved to: results/BATCH_TIMESTAMP_MODEL/batch_PROVIDER_MODEL/"
echo ""
echo "Next: Wait for batch jobs to complete, then run ablation_study_evaluate.sh"
echo ""
